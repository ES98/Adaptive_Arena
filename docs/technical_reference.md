# Adaptive Arena: Technical Reference

## 1. System Overview
**Adaptive Arena** is a next-generation memory management system designed for high-throughput, low-latency applications. It replaces standard `malloc/free` with a smart, learning-based allocation strategy that adapts to system jitter and data bursts.

### Core Philosophy
- **Predictive Allocation**: Uses Exponential Moving Average (EMA) to predict future memory needs.
- **Zero-Copy**: Maximizes direct hardware access (GPU/DMA) to eliiminate redundant memory copies.
- **Hybrid Acceleration**: Automatically switches between CUDA Pinned Memory and OS Pinned Memory based on hardware availability.

---

## 2. Core Architecture

### 2.1. Adaptive Resource (PMR)
Built on C++17 `std::pmr::memory_resource`, the core resource manages memory chunks ("Super-Pages") efficiently.
- **Learning Engine**: Tracks peak usage windows and predicts future load using an EMA model ($ \alpha = 0.1 \sim 0.3 $).
- **Persistence**: Saves learned usage patterns to disk (`adaptive_arena.json` / `bin`), allowing the application to "warm up" instantly upon restart.

### 2.2. Ultrasound RF Mode (Specialized)
A dedicated mode for processing raw Ultrasound Radio-Frequency (RF) data streams.
- **Structure of Arrays (SoA)**: 
    - **Headers** (Metadata): Stored in CPU-cache optimized contiguous blocks.
    - **Payloads** (RF Signal): Stored in Page-Locked (Pinned) memory for high-speed transfer.
- **Jitter-Adaptive Ring Buffer**:
    - Monitors "Processing Lag" (Write Cursor - Read Cursor).
    - **Elastic Expansion**: If system jitter increases, the ring buffer automatically expands its slot count to absorb the latency spikes, preventing data loss.

---

## 3. Hybrid Acceleration Strategy
The system features a robust **Runtime Detection** mechanism to ensure optimal performance on any hardware.

| Hardware State | Backend | Description |
| :--- | :--- | :--- |
| **NVIDIA GPU** | `cudaHostAlloc` | **Zero-Copy**. GPU can read system memory directly via PCIe No copies required. |
| **CPU Only** | `VirtualAlloc` | **OS Pinned**. Pages are locked in physical RAM, preventing swapping and ensuring stable access times. |

- **Mechanism**: The `CudaWrapper` dynamically loads `nvcuda.dll` at runtime. If found, it enables CUDA paths; otherwise, it falls back to Windows API.

---

## 4. Performance Metrics
Real-time telemetry offers deep insights into system performance.

### 4.1. Allocation Latency
- **Resolution**: Nanoseconds (ns).
- **Metric**: Tracks the time cost of every `do_allocate` call.
- **Benefit**: Demonstrates that Arena allocation is consistently faster and more deterministic than heap allocation (`new/malloc`), especially under fragmentation.

### 4.2. Throughput (GB/s)
- **Resolution**: Gigabytes per second.
- **Metric**: EMA-smoothed data rate based on frame size and processing frequency.
- **Constraint**: Designed to handle 5GB/s+ sustained throughput for real-time beamforming applications.

---

## 5. Usage Guide
### Dashboard Controls
- **Reset Learning**: Clears the EMA history and resets the ring buffer to initial state.
- **Force Save**: Manually commits the current learning state to disk.
- **Simulate Jitter**: A slider in the "Debug" panel simulates processing delays to test the ring buffer's elastic expansion.

---
*Generated by Adaptive Arena Team*
